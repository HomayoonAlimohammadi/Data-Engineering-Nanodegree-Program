{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg2\n",
    "import json\n",
    "from typing import Tuple\n",
    "from psycopg2.extensions import cursor, connection\n",
    "\n",
    "\n",
    "def load_credentials(path: str) -> Tuple[str, str, str]:\n",
    "    \"Extract db credentials from json file.\"\n",
    "    try:\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "            USER = data['username']\n",
    "            PASS = data['password']\n",
    "            NAME = data['name']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    return (NAME, USER, PASS)\n",
    "\n",
    "def create_connect_db(NAME: str, USER: str, PASS: str) -> Tuple[connection, cursor]:\n",
    "    \"Stablish connection and cursor to db given the credentials.\"\n",
    "    try:\n",
    "        conn = pg2.connect(\n",
    "            host='localhost',\n",
    "            database=NAME,\n",
    "            user=USER,\n",
    "            password=PASS,\n",
    "        )\n",
    "        conn.set_session(autocommit=True)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        cur.execute(\"DROP DATABASE IF EXISTS sparkifydb\")\n",
    "        cur.execute(\"CREATE DATABASE sparkifydb WITH ENCODING 'utf8' TEMPLATE template0\")\n",
    "\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "        conn = pg2.connect(\n",
    "            host='localhost',\n",
    "            database='sparkifydb',\n",
    "            user=USER,\n",
    "            password=PASS\n",
    "        )\n",
    "        conn.set_session(autocommit=True)\n",
    "        cur = conn.cursor()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return (conn, cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './db_credentials.json'\n",
    "NAME, USER, PASS = load_credentials(path)\n",
    "conn, cur = create_connect_db(NAME, USER, PASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DROP and CREATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_songplays = \"DROP TABLE IF EXISTS songplays\"\n",
    "\n",
    "create_songplays = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS songplays (\n",
    "    songplay_id SERIAL PRIMARY KEY,\n",
    "    start_time TIMESTAMP,\n",
    "    user_id INT,\n",
    "    level VARCHAR(10),\n",
    "    song_id VARCHAR(20),\n",
    "    artist_id VARCHAR(20),\n",
    "    session_id INT,\n",
    "    location VARCHAR(50),\n",
    "    user_agent VARCHAR(150)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "drop_users = \"DROP TABLE IF EXISTS users\"\n",
    "\n",
    "create_users = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "    user_id INT PRIMARY KEY,\n",
    "    first_name VARCHAR(50),\n",
    "    last_name VARCHAR(50),\n",
    "    gender CHAR(1),\n",
    "    level VARCHAR(10)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "drop_songs = \"DROP TABLE IF EXISTS songs\"\n",
    "\n",
    "create_songs = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS songs (\n",
    "    song_id VARCHAR(20) PRIMARY KEY,\n",
    "    title VARCHAR(100),\n",
    "    artist_id VARCHAR(20) NOT NULL,\n",
    "    year INT,\n",
    "    duration FLOAT(5)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "drop_artists = \"DROP TABLE IF EXISTS artists\"\n",
    "\n",
    "create_artists = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS artists (\n",
    "    artist_id VARCHAR(20) PRIMARY KEY,\n",
    "    name VARCHAR(100),\n",
    "    location VARCHAR(100),\n",
    "    latitude FLOAT(5),\n",
    "    longitude FLOAT(5)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "drop_time = \"DROP TABLE IF EXISTS time\"\n",
    "\n",
    "create_time = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS time (\n",
    "    start_time TIMESTAMP PRIMARY KEY,\n",
    "    hour INT,\n",
    "    day INT,\n",
    "    week SMALLINT,\n",
    "    month SMALLINT,\n",
    "    year SMALLINT,\n",
    "    weekday SMALLINT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "drop_queries = [drop_songplays, drop_songs, drop_artists, drop_time, drop_users]\n",
    "create_queries = [create_songplays, create_songs, create_artists, create_time, create_users]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DROP and CREATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in drop_queries:\n",
    "    \"DROP TABLE IF EXISTS ...\"\n",
    "    try:\n",
    "        cur.execute(query)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "for query in create_queries:\n",
    "    \"CREATE TABLE IF NOT EXISTS ...\"\n",
    "    try:\n",
    "        cur.execute(query)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERT INTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_songplays = (\"\"\"\n",
    "INSERT INTO songplays\n",
    "(start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)\n",
    "VALUES \n",
    "(%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\")\n",
    "\n",
    "insert_users = (\"\"\"\n",
    "INSERT INTO users (user_id, first_name, last_name, gender, level)\n",
    "VALUES (%s, %s, %s, %s, %s) ON CONFLICT (user_id) DO UPDATE SET level = EXCLUDED.level;\n",
    "\"\"\")\n",
    "\n",
    "insert_songs = (\"\"\"\n",
    "INSERT INTO songs (song_id, title, artist_id, year, duration)\n",
    "VALUES (%s, %s, %s, %s, %s) ON CONFLICT DO NOTHING;\n",
    "\"\"\")\n",
    "\n",
    "insert_artists = (\"\"\"\n",
    "INSERT INTO artists (artist_id, name, location, latitude, longitude)\n",
    "VALUES (%s, %s, %s, %s, %s) ON CONFLICT DO NOTHING;\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "insert_time = (\"\"\"\n",
    "INSERT INTO time (start_time, hour, day, week, month, year, weekday)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s) ON CONFLICT DO NOTHING;\n",
    "\"\"\")\n",
    "\n",
    "INSERT = {\n",
    "    'songplays': insert_songplays,\n",
    "    'users': insert_users,\n",
    "    'time': insert_time,\n",
    "    'artists': insert_artists,\n",
    "    'sogns': insert_songs,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: test_songplays\n",
      "(0,)\n",
      "Table: test_users\n",
      "(0,)\n",
      "Table: test_artists\n",
      "(0,)\n",
      "Table: test_songs\n",
      "(0,)\n",
      "Table: test_time\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "test_songplays = \"SELECT COUNT(*) FROM songplays\"\n",
    "\n",
    "test_users = \"SELECT COUNT(*) FROM users\"\n",
    "\n",
    "test_artists = \"SELECT COUNT(*) FROM artists\"\n",
    "\n",
    "test_songs = \"SELECT COUNT(*) FROM songs\"\n",
    "\n",
    "test_time = \"SELECT COUNT(*) FROM time\"\n",
    "\n",
    "\n",
    "test_queries = [test_songplays, test_users, test_artists, test_songs, test_time]\n",
    "table_names = ['test_songplays', 'test_users', 'test_artists', 'test_songs', 'test_time']\n",
    "\n",
    "for table_name, query in zip(table_names, test_queries):\n",
    "    try:\n",
    "        cur.execute(query)\n",
    "        row = cur.fetchone()\n",
    "\n",
    "        print('Table:', table_name)\n",
    "        if not row:\n",
    "            print('No data yet.\\n')\n",
    "        while row:\n",
    "            print(row)\n",
    "            row = cur.fetchone()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELECT specific song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_song = \"\"\"\n",
    "SELECT songs.song_id, artists.artist_id FROM songs\n",
    "JOIN artists ON songs.artist_id = artists.artist_id\n",
    "WHERE songs.title = %s\n",
    "AND artists.name = %s\n",
    "AND songs.duration = %s\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./song_data/A/B/B/TRABBAM128F429D223.json', './song_data/A/B/B/TRABBNP128F932546F.json', './song_data/A/B/B/TRABBXU128F92FEF48.json', './song_data/A/B/B/TRABBOR128F4286200.json', './song_data/A/B/B/TRABBVJ128F92F7EAA.json']\n",
      "\n",
      "['./log_data/2018/11/2018-11-07-events.json', './log_data/2018/11/2018-11-22-events.json', './log_data/2018/11/2018-11-18-events.json', './log_data/2018/11/2018-11-04-events.json', './log_data/2018/11/2018-11-01-events.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import List\n",
    "\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "def get_all_files(path: str) -> List[str]:\n",
    "    all_files = []\n",
    "    for root, sub_dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                all_files.append(file_path)\n",
    "\n",
    "    return all_files\n",
    "\n",
    "song_path = './song_data/'\n",
    "song_files = get_all_files(song_path)\n",
    "\n",
    "log_path = './log_data/'\n",
    "log_files = get_all_files(log_path)\n",
    "\n",
    "print(song_files[:5])\n",
    "print()\n",
    "print(log_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sample_song = pd.read_json(song_files[0], lines=True)\n",
    "sample_log = pd.read_json(log_files[0], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_songs</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ARBGXIG122988F409D</td>\n",
       "      <td>37.77916</td>\n",
       "      <td>-122.42005</td>\n",
       "      <td>California - SF</td>\n",
       "      <td>Steel Rain</td>\n",
       "      <td>SOOJPRH12A8C141995</td>\n",
       "      <td>Loaded Like A Gun</td>\n",
       "      <td>173.19138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_songs           artist_id  artist_latitude  artist_longitude  \\\n",
       "0          1  ARBGXIG122988F409D         37.77916        -122.42005   \n",
       "\n",
       "   artist_location artist_name             song_id              title  \\\n",
       "0  California - SF  Steel Rain  SOOJPRH12A8C141995  Loaded Like A Gun   \n",
       "\n",
       "    duration  year  \n",
       "0  173.19138     0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_song.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miami Horror</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kate</td>\n",
       "      <td>F</td>\n",
       "      <td>88</td>\n",
       "      <td>Harrell</td>\n",
       "      <td>250.8273</td>\n",
       "      <td>paid</td>\n",
       "      <td>Lansing-East Lansing, MI</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540473e+12</td>\n",
       "      <td>293</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>200</td>\n",
       "      <td>1541548876796</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist       auth firstName gender  itemInSession lastName    length  \\\n",
       "0  Miami Horror  Logged In      Kate      F             88  Harrell  250.8273   \n",
       "\n",
       "  level                  location method      page  registration  sessionId  \\\n",
       "0  paid  Lansing-East Lansing, MI    PUT  NextSong  1.540473e+12        293   \n",
       "\n",
       "        song  status             ts  \\\n",
       "0  Sometimes     200  1541548876796   \n",
       "\n",
       "                                           userAgent userId  \n",
       "0  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...     97  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_log.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERT files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_songs_data(song_files: List[str], cur=cur, base_query=insert_songs) -> None:\n",
    "    for path in song_files:\n",
    "        df = pd.read_json(path, lines=True)\n",
    "        data = df[['song_id', 'title', 'artist_id', 'year', 'duration']].values[0].tolist()\n",
    "        cur.execute(base_query, data)\n",
    "\n",
    "insert_songs_data(song_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_user_data(log_files: List[str], cur=cur, base_query=insert_users) -> None:\n",
    "    for path in log_files:\n",
    "        df = pd.read_json(path, lines=True)\n",
    "        data = df[['userId', 'firstName', 'lastName', 'gender', 'level']].values[0].tolist()\n",
    "        if data[0] == '':\n",
    "            continue\n",
    "        cur.execute(base_query, data)\n",
    "\n",
    "insert_user_data(log_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_artists_data(song_files: List[str], base_query=insert_artists) -> None:\n",
    "    for path in song_files:\n",
    "        df = pd.read_json(path, lines=True)\n",
    "        data = df[['artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude']].values[0].tolist()\n",
    "        cur.execute(base_query, data)\n",
    "\n",
    "insert_artists_data(song_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_time_data(log_files: List[str], base_query=insert_time) -> None:\n",
    "    for path in log_files:\n",
    "        df = pd.read_json(path, lines=True)\n",
    "        df = df[df['page'] == 'NextSong']\n",
    "        df['ts'] = pd.to_datetime(df['ts'], unit='ms')\n",
    "        for row_idx in range(len(df)):\n",
    "            start_time = df['ts'].iloc[row_idx]\n",
    "            data = [start_time, start_time.hour, start_time.day, start_time.week, start_time.month, start_time.year, start_time.weekday()]\n",
    "            cur.execute(base_query, data)\n",
    "\n",
    "insert_time_data(log_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_songplay_data(log_files: List[str], base_query=insert_songplays) -> None:\n",
    "\n",
    "    for path in log_files:\n",
    "        df = pd.read_json(path, lines=True)\n",
    "        df = df[df['page'] == 'NextSong']\n",
    "        df['ts'] = pd.to_datetime(df['ts'], unit='ms')\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            cur.execute(select_song, (row.song, row.artist, row.length))\n",
    "            results = cur.fetchone()\n",
    "            song_id, artist_id = None, None\n",
    "            if results:\n",
    "                song_id, artist_id = results\n",
    "\n",
    "            songplay_data = (row.ts, row.userId, row.level, song_id, \\\n",
    "                             artist_id, row.sessionId, row.location, row.userAgent)\n",
    "            \n",
    "            cur.execute(base_query, songplay_data)\n",
    "\n",
    "insert_songplay_data(log_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: test_songplays\n",
      "(6820,)\n",
      "Table: test_users\n",
      "(25,)\n",
      "Table: test_artists\n",
      "(69,)\n",
      "Table: test_songs\n",
      "(71,)\n",
      "Table: test_time\n",
      "(6813,)\n"
     ]
    }
   ],
   "source": [
    "for table_name, query in zip(table_names, test_queries):\n",
    "    try:\n",
    "        cur.execute(query)\n",
    "        row = cur.fetchone()\n",
    "\n",
    "        print('Table:', table_name)\n",
    "        if not row:\n",
    "            print('No data yet.\\n')\n",
    "        while row:\n",
    "            print(row)\n",
    "            row = cur.fetchone()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to databse was closed successfully.\n"
     ]
    }
   ],
   "source": [
    "def close_db(conn, cur) -> None:\n",
    "    \"Drop db and tables, close connection and cursor.\"\n",
    "    for query in drop_queries:\n",
    "        cur.execute(query)\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    NAME, USER, PASS = load_credentials('./db_credentials.json')\n",
    "    conn = pg2.connect(database=NAME, user=USER, password=PASS)\n",
    "    conn.set_session(autocommit=True)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('DROP DATABASE IF EXISTS sparkifydb')\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print('Connection to databse was closed successfully.')\n",
    "\n",
    "close_db(conn, cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
